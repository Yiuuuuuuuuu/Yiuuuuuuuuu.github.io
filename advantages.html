<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advantages & Challenges | Computational Linguistics</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <header>
        <h1>CS1102 - Computational Linguistics: Advantages & Challenges</h1>
        <div class="group-info">
            <p>Group Members: Luk Cheuk Yiu 57881645, Choi Cheuk Yin 57274102, Wong Tsz Mei 57186243, Shin Chun Lung 58020740</p>
            <p>Techniques Demonstrated: HTML / CSS / Javascript</p>
        </div>
    </header>

    <nav class="dropdown">
        <button class="dropbtn">Menu</button>
        <div class="dropdown-content">
          <a href="index.html">Home</a>
          <a href="advantages.html">Advantage & Challenge</a>
          <a href="transformation.html">Comparison & Transformation</a>
          <a href="conclusion.html">Future Development & Conclusion</a>
          <a href="references.html">References</a>
        </div>
    </nav>

    <main>
        <!-- Advantage & Challenge -->
        <section>
            <h2>Advantages of LLMs</h2>
            <h3>Contextual and semantic understanding:</h3>
            <p>Transformer architectures are used to capture contextual aspects and complicated linguistic patterns, improving their comprehension of difficult phrases and facilitating the creation and translation of coherent texts, including lengthy ones (up to 512 words).</p>
            
            <h3>Scalability</h3>
            <p>LLMs offer unmatched scalability, processing thousands of simultaneous queries via cloud computing. They enable 24/7 automation for customer service and content generation while maintaining performance under heavy loads. With sub-linear cost growth, they outperform traditional solutions, efficiently handling enterprise demands and traffic spikes across industries. Their parallel processing ensures consistent, low-latency responses at scale.</p>
        </section>

        <section>
            <h2>Drawback of LLMs</h2>
            <h3>Hallucination</h3>
            <p>It may provide misleading information that sounds trustworthy. In vital professions like law and medical, LLMs may confidently generate erroneous results since they use statistical prediction of text rather than fact extraction. Because LLMs do not have real-time fact-checking, they may make mistakes that could be detrimental, in contrast to typical expert systems that have verified databases. Despite the benefits of methods such as retrieval-augmented generation, hallucinations are still a problem that needs to be verified by humans, especially in high-stakes applications.</p>
            
            <h3>Ethical concerns</h3>
            <p>LLMs raise a variety of significant ethical problems. First, through their outputs, they reinforce negative stereotypes by systematically spreading and amplifying societal prejudices present in their training corpora. Second, they have a significant influence on the environment due to the large computational resources needed for their creation and operation. These models' upkeep and training-related carbon emissions contribute disproportionately to climate change. Despite being marketed as socially beneficial technologies, artificial intelligence systems concurrently perpetuate discriminatory practices and worsen ecological degradation, creating a moral quandary.</p>
        </section>

        <section>
            <h2>Challenges of LLMs</h2>
            <h3>High Cost</h3>
            <p>Compared to standard models, LLMs are significantly more costly to train, infer, and maintain. While traditional models like BERT require only hundreds of computations, training an LLM might cost millions due to its high computing demands. Additionally, running LLMs can be expensive; compared to simpler models, inference fees might be up to 100,000 times higher for each query. LLMs also require costly infrastructure and ongoing optimization, while classical models function well with simple technology. The reason for these high costs is that LLMs are much more resource-intensive than traditional machine learning techniques, despite their great size, specific hardware requirements, and massive data requirements.</p>
            
            <h3>Reliability</h3>
            <p>LLMs may produce harmful or illegal content in addition to providing insufficient protections for children. Even in the absence of clear cues, LLMs may unintentionally generate violent, pornographic, or hazardous content because they make text predictions based on unfiltered training data. Since most systems don't have child-specific filters or real-time age verification, improper comments can appear before moderation. LLMs frequently rely on post-generation checks, which leaves children susceptible, in contrast to search engines that have safeguards like SafeSearch. While accurate, naive hallucinations can create risky recommendations, young users may also trust AI results. Without stricter age and content filters, children run the risk of being exposed to harmful content that could have negative psychological or legal repercussions.</p>
        </section>
    </main>
    <footer>
        <p>&copy; 2024 CS1102 Group Project - Computational Linguistics</p>
    </footer>
</body>
</html>